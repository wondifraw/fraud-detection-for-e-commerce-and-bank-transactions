{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c2ffea",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d580fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load the processed data\n",
    "fraud_data = pd.read_csv('../data/processed/fraud_one_hot_encoded.csv')\n",
    "credit_data = pd.read_csv('../data/processed/credit_minmax_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d2b97",
   "metadata": {},
   "source": [
    "## Appending root directory amd autoloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa50140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851dc3d4",
   "metadata": {},
   "source": [
    "## Spliting Fraud data as training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146f5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_split import DataSplitter\n",
    "\n",
    "# For fraud_data, assume target column is 'class'\n",
    "X_fraud, y_fraud = DataSplitter.separate_features_and_target(fraud_data, target_col='class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded1fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For credit_data, assume target column is 'Class'\n",
    "X_credit, y_credit = DataSplitter.separate_features_and_target(credit_data, target_col='Class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4389f",
   "metadata": {},
   "source": [
    "### Training and evaluating Logistic regretion with Fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in y_train before SMOTE: {1: 11321, 0: 11320}\n",
      "Columns used for modeling: ['user_id', 'purchase_value', 'age', 'ip_address', 'ip_int', 'hour_of_day', 'day_of_week', 'transaction_count']\n",
      "Class distribution in y_train after SMOTE: {0: 11321, 1: 11321}\n",
      "Logistic Regression on processed fraud data:\n",
      "accuracy: 0.5046811517399753\n",
      "precision: 0.5042819499341239\n",
      "recall: 0.5409893992932863\n",
      "f1: 0.5219911353562905\n",
      "roc_auc: 0.5063436985519981\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.5051428571428571, 'recall': 0.46838572942423173, 'f1-score': 0.48607038123167157, 'support': 2831.0}, '1': {'precision': 0.5042819499341239, 'recall': 0.5409893992932863, 'f1-score': 0.5219911353562905, 'support': 2830.0}, 'accuracy': 0.5046811517399753, 'macro avg': {'precision': 0.5047124035384905, 'recall': 0.5046875643587589, 'f1-score': 0.504030758293981, 'support': 5661.0}, 'weighted avg': {'precision': 0.5047124795769298, 'recall': 0.5046811517399753, 'f1-score': 0.5040275856430249, 'support': 5661.0}}\n"
     ]
    }
   ],
   "source": [
    "from scripts.logistic_regression import run_logistic_regression\n",
    "\n",
    "# Use the processed fraud data from the data/processed directory\n",
    "fraud_data_path = '../data/processed/fraud_one_hot_encoded.csv'\n",
    "\n",
    "# Run logistic regression on the processed fraud data\n",
    "fraud_logreg_metrics = run_logistic_regression(fraud_data_path, target_col='class')\n",
    "\n",
    "# Display the results\n",
    "print(\"Logistic Regression on processed fraud data:\")\n",
    "for metric, value in fraud_logreg_metrics.items():\n",
    "    if metric != 'classification_report':\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(value)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the trained logistic regression model to a file\n",
    "# We need to retrain the model here to get the fitted model object\n",
    "from scripts.logistic_regression import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "fraud_df = pd.read_csv(fraud_data_path)\n",
    "from src.data_split import DataSplitter\n",
    "X, y = DataSplitter.separate_features_and_target(fraud_df, target_col='class')\n",
    "\n",
    "# Only keep numeric columns for modeling (as in the script)\n",
    "X_numeric = X.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Split the data (as in the script)\n",
    "splitter = DataSplitter()\n",
    "X_train, X_test, y_train, y_test = splitter.train_test_split(X_numeric, y, test_size=0.2, random_state=42, stratify=True)\n",
    "\n",
    "# Handle imbalance (as in the script)\n",
    "from scripts.logistic_regression import ImbalanceHandler\n",
    "imbalance_handler = ImbalanceHandler()\n",
    "X_train_bal, y_train_bal = imbalance_handler.apply_smote(X_train, y_train)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'fraud_logreg_model.joblib')\n",
    "print(\"Trained logistic regression model saved as 'fraud_logreg_model.joblib'\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffc169",
   "metadata": {},
   "source": [
    "### Training and evaluating Logistic regretion with Credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce1b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from: ../data/processed/credit_minmax_scaled.csv\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283726 entries, 0 to 283725\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    283726 non-null  float64\n",
      " 1   V1      283726 non-null  float64\n",
      " 2   V2      283726 non-null  float64\n",
      " 3   V3      283726 non-null  float64\n",
      " 4   V4      283726 non-null  float64\n",
      " 5   V5      283726 non-null  float64\n",
      " 6   V6      283726 non-null  float64\n",
      " 7   V7      283726 non-null  float64\n",
      " 8   V8      283726 non-null  float64\n",
      " 9   V9      283726 non-null  float64\n",
      " 10  V10     283726 non-null  float64\n",
      " 11  V11     283726 non-null  float64\n",
      " 12  V12     283726 non-null  float64\n",
      " 13  V13     283726 non-null  float64\n",
      " 14  V14     283726 non-null  float64\n",
      " 15  V15     283726 non-null  float64\n",
      " 16  V16     283726 non-null  float64\n",
      " 17  V17     283726 non-null  float64\n",
      " 18  V18     283726 non-null  float64\n",
      " 19  V19     283726 non-null  float64\n",
      " 20  V20     283726 non-null  float64\n",
      " 21  V21     283726 non-null  float64\n",
      " 22  V22     283726 non-null  float64\n",
      " 23  V23     283726 non-null  float64\n",
      " 24  V24     283726 non-null  float64\n",
      " 25  V25     283726 non-null  float64\n",
      " 26  V26     283726 non-null  float64\n",
      " 27  V27     283726 non-null  float64\n",
      " 28  V28     283726 non-null  float64\n",
      " 29  Amount  283726 non-null  float64\n",
      " 30  Class   283726 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.1 MB\n",
      "None\n",
      "\n",
      "Columns in DataFrame: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "\n",
      "Found target column 'Class' (case-insensitive match for 'class')\n",
      "\n",
      "Class distribution in y_train before SMOTE: {0: 226602, 1: 378}\n",
      "\n",
      "Columns used for modeling: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "Class distribution in y_train after SMOTE: {0: 226602, 1: 226602}\n",
      "Logistic Regression on processed fraud data:\n",
      "accuracy: 0.9758397067634723\n",
      "precision: 0.057558945908460474\n",
      "recall: 0.8736842105263158\n",
      "f1: 0.10800260247234873\n",
      "roc_auc: 0.9600000557429655\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.9997830175032547, 'recall': 0.9760110148099769, 'f1-score': 0.9877540083069091, 'support': 56651.0}, '1': {'precision': 0.057558945908460474, 'recall': 0.8736842105263158, 'f1-score': 0.10800260247234873, 'support': 95.0}, 'accuracy': 0.9758397067634723, 'macro avg': {'precision': 0.5286709817058576, 'recall': 0.9248476126681464, 'f1-score': 0.5478783053896289, 'support': 56746.0}, 'weighted avg': {'precision': 0.9982056149233106, 'recall': 0.9758397067634723, 'f1-score': 0.9862811928916502, 'support': 56746.0}}\n"
     ]
    }
   ],
   "source": [
    "from scripts.logistic_regression import run_logistic_regression\n",
    "\n",
    "# Use the processed fraud data from the data/processed directory\n",
    "fraud_data_path = '../data/processed/credit_minmax_scaled.csv'\n",
    "\n",
    "# Run logistic regression on the processed fraud data\n",
    "fraud_logreg_metrics = run_logistic_regression(fraud_data_path, target_col='class')\n",
    "\n",
    "# Display the results\n",
    "print(\"Logistic Regression on processed fraud data:\")\n",
    "for metric, value in fraud_logreg_metrics.items():\n",
    "    if metric != 'classification_report':\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafe72a",
   "metadata": {},
   "source": [
    "### Training and evaluating Lightgbm with fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5c47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from: ../data/processed/fraud_one_hot_encoded.csv\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28302 entries, 0 to 28301\n",
      "Columns: 164 entries, user_id to country_Zimbabwe\n",
      "dtypes: bool(152), float64(7), int64(2), object(3)\n",
      "memory usage: 6.7+ MB\n",
      "None\n",
      "\n",
      "Columns in DataFrame: ['user_id', 'signup_time', 'purchase_time', 'purchase_value', 'device_id', 'age', 'ip_address', 'class', 'ip_int', 'hour_of_day', 'day_of_week', 'transaction_count', 'source_Ads', 'source_Direct', 'source_SEO', 'browser_Chrome', 'browser_FireFox', 'browser_IE', 'browser_Opera', 'browser_Safari', 'sex_F', 'sex_M', 'country_Afghanistan', 'country_Albania', 'country_Algeria', 'country_Angola', 'country_Argentina', 'country_Armenia', 'country_Australia', 'country_Austria', 'country_Azerbaijan', 'country_Bahrain', 'country_Bangladesh', 'country_Barbados', 'country_Belarus', 'country_Belgium', 'country_Benin', 'country_Bermuda', 'country_Bolivia', 'country_Bosnia and Herzegowina', 'country_Botswana', 'country_Brazil', 'country_Brunei Darussalam', 'country_Bulgaria', 'country_Cambodia', 'country_Canada', 'country_Cayman Islands', 'country_Chile', 'country_China', 'country_Colombia', 'country_Costa Rica', \"country_Cote D'ivoire\", 'country_Croatia (LOCAL Name: Hrvatska)', 'country_Cuba', 'country_Cyprus', 'country_Czech Republic', 'country_Denmark', 'country_Dominican Republic', 'country_Ecuador', 'country_Egypt', 'country_El Salvador', 'country_Estonia', 'country_Ethiopia', 'country_European Union', 'country_Fiji', 'country_Finland', 'country_France', 'country_Gabon', 'country_Georgia', 'country_Germany', 'country_Greece', 'country_Guatemala', 'country_Honduras', 'country_Hong Kong', 'country_Hungary', 'country_Iceland', 'country_India', 'country_Indonesia', 'country_Iran (ISLAMIC Republic Of)', 'country_Iraq', 'country_Ireland', 'country_Israel', 'country_Italy', 'country_Japan', 'country_Jordan', 'country_Kazakhstan', 'country_Kenya', 'country_Korea Republic of', 'country_Kuwait', 'country_Kyrgyzstan', 'country_Latvia', 'country_Lebanon', 'country_Libyan Arab Jamahiriya', 'country_Lithuania', 'country_Luxembourg', 'country_Macau', 'country_Macedonia', 'country_Malawi', 'country_Malaysia', 'country_Malta', 'country_Mauritius', 'country_Mexico', 'country_Moldova Republic of', 'country_Montenegro', 'country_Morocco', 'country_Mozambique', 'country_Namibia', 'country_Nepal', 'country_Netherlands', 'country_New Zealand', 'country_Nicaragua', 'country_Nigeria', 'country_Norway', 'country_Oman', 'country_Pakistan', 'country_Palestinian Territory Occupied', 'country_Panama', 'country_Papua New Guinea', 'country_Paraguay', 'country_Peru', 'country_Philippines', 'country_Poland', 'country_Portugal', 'country_Puerto Rico', 'country_Qatar', 'country_Reunion', 'country_Romania', 'country_Russian Federation', 'country_Rwanda', 'country_Saint Martin', 'country_Saudi Arabia', 'country_Senegal', 'country_Serbia', 'country_Seychelles', 'country_Singapore', 'country_Slovakia (SLOVAK Republic)', 'country_Slovenia', 'country_South Africa', 'country_South Sudan', 'country_Spain', 'country_Sri Lanka', 'country_Sudan', 'country_Sweden', 'country_Switzerland', 'country_Syrian Arab Republic', 'country_Taiwan; Republic of China (ROC)', 'country_Tanzania United Republic of', 'country_Thailand', 'country_Trinidad and Tobago', 'country_Tunisia', 'country_Turkey', 'country_Turkmenistan', 'country_Uganda', 'country_Ukraine', 'country_United Arab Emirates', 'country_United Kingdom', 'country_United States', 'country_Unknown', 'country_Uruguay', 'country_Uzbekistan', 'country_Venezuela', 'country_Viet Nam', 'country_Virgin Islands (U.S.)', 'country_Zimbabwe']\n",
      "\n",
      "Class distribution in y_train before SMOTE: {1: 11321, 0: 11320}\n",
      "\n",
      "Columns used for modeling: ['user_id', 'purchase_value', 'age', 'ip_address', 'ip_int', 'hour_of_day', 'day_of_week', 'transaction_count']\n",
      "Class distribution in y_train after SMOTE: {0: 11321, 1: 11321}\n",
      "lightgbm on processed fraud data:\n",
      "accuracy: 0.6543013601837131\n",
      "precision: 0.6545132743362831\n",
      "recall: 0.653356890459364\n",
      "f1: 0.6539345711759504\n",
      "roc_auc: 0.7105776155711687\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.6540902679830748, 'recall': 0.6552454962910632, 'f1-score': 0.6546673725074995, 'support': 2831.0}, '1': {'precision': 0.6545132743362831, 'recall': 0.653356890459364, 'f1-score': 0.6539345711759504, 'support': 2830.0}, 'accuracy': 0.6543013601837131, 'macro avg': {'precision': 0.654301771159679, 'recall': 0.6543011933752136, 'f1-score': 0.654300971841725, 'support': 5661.0}, 'weighted avg': {'precision': 0.6543017337982275, 'recall': 0.6543013601837131, 'f1-score': 0.6543010365653896, 'support': 5661.0}}\n"
     ]
    }
   ],
   "source": [
    "from scripts.lightgbm_model import run_lightgbm\n",
    "\n",
    "# Use the processed fraud data from the data/processed directory\n",
    "fraud_data_path = '../data/processed/fraud_one_hot_encoded.csv'\n",
    "\n",
    "# Run lightgbm on the processed fraud data\n",
    "fraud_logreg_metrics = run_lightgbm(fraud_data_path, target_col='class')\n",
    "\n",
    "# Display the results\n",
    "print(\"lightgbm on processed fraud data:\")\n",
    "for metric, value in fraud_logreg_metrics.items():\n",
    "    if metric != 'classification_report':\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937b7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "325ee60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM model saved to ../model\\logreg_credit_20250721_163443.joblib\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training to get the model object for saving\n",
    "from scripts.lightgbm_model import DataSplitter, ImbalanceHandler\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "df = pd.read_csv(fraud_data_path)\n",
    "splitter = DataSplitter()\n",
    "imbalance_handler = ImbalanceHandler()\n",
    "\n",
    "# Find the correct target column (case-insensitive)\n",
    "target_col = 'class'\n",
    "if target_col not in df.columns:\n",
    "    for col in df.columns:\n",
    "        if col.lower() == target_col.lower():\n",
    "            target_col = col\n",
    "            break\n",
    "\n",
    "X, y = splitter.separate_features_and_target(df, target_col)\n",
    "X_train, X_test, y_train, y_test = splitter.train_test_split(X, y, test_size=0.2, random_state=42, stratify=True)\n",
    "X_train_numeric = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64', 'int64'])\n",
    "X_train_bal, y_train_bal = imbalance_handler.apply_smote(X_train_numeric, y_train)\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "joblib.dump(model, os.path.join(model_dir, model_filename))\n",
    "print(f\"LightGBM model saved to {os.path.join(model_dir, model_filename)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d516ab",
   "metadata": {},
   "source": [
    "### Training and evaluating Lightgbm with Credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07208dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from: ../data/processed/credit_minmax_scaled.csv\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283726 entries, 0 to 283725\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    283726 non-null  float64\n",
      " 1   V1      283726 non-null  float64\n",
      " 2   V2      283726 non-null  float64\n",
      " 3   V3      283726 non-null  float64\n",
      " 4   V4      283726 non-null  float64\n",
      " 5   V5      283726 non-null  float64\n",
      " 6   V6      283726 non-null  float64\n",
      " 7   V7      283726 non-null  float64\n",
      " 8   V8      283726 non-null  float64\n",
      " 9   V9      283726 non-null  float64\n",
      " 10  V10     283726 non-null  float64\n",
      " 11  V11     283726 non-null  float64\n",
      " 12  V12     283726 non-null  float64\n",
      " 13  V13     283726 non-null  float64\n",
      " 14  V14     283726 non-null  float64\n",
      " 15  V15     283726 non-null  float64\n",
      " 16  V16     283726 non-null  float64\n",
      " 17  V17     283726 non-null  float64\n",
      " 18  V18     283726 non-null  float64\n",
      " 19  V19     283726 non-null  float64\n",
      " 20  V20     283726 non-null  float64\n",
      " 21  V21     283726 non-null  float64\n",
      " 22  V22     283726 non-null  float64\n",
      " 23  V23     283726 non-null  float64\n",
      " 24  V24     283726 non-null  float64\n",
      " 25  V25     283726 non-null  float64\n",
      " 26  V26     283726 non-null  float64\n",
      " 27  V27     283726 non-null  float64\n",
      " 28  V28     283726 non-null  float64\n",
      " 29  Amount  283726 non-null  float64\n",
      " 30  Class   283726 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.1 MB\n",
      "None\n",
      "\n",
      "Columns in DataFrame: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "\n",
      "Found target column 'Class' (case-insensitive match for 'class')\n",
      "\n",
      "Class distribution in y_train before SMOTE: {0: 226602, 1: 378}\n",
      "\n",
      "Columns used for modeling: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "Class distribution in y_train after SMOTE: {0: 226602, 1: 226602}\n",
      "lightgbm on processed fraud data:\n",
      "accuracy: 0.9758397067634723\n",
      "precision: 0.057558945908460474\n",
      "recall: 0.8736842105263158\n",
      "f1: 0.10800260247234873\n",
      "roc_auc: 0.9600000557429655\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.9997830175032547, 'recall': 0.9760110148099769, 'f1-score': 0.9877540083069091, 'support': 56651.0}, '1': {'precision': 0.057558945908460474, 'recall': 0.8736842105263158, 'f1-score': 0.10800260247234873, 'support': 95.0}, 'accuracy': 0.9758397067634723, 'macro avg': {'precision': 0.5286709817058576, 'recall': 0.9248476126681464, 'f1-score': 0.5478783053896289, 'support': 56746.0}, 'weighted avg': {'precision': 0.9982056149233106, 'recall': 0.9758397067634723, 'f1-score': 0.9862811928916502, 'support': 56746.0}}\n",
      "Model saved to ../model\\logreg_credit_20250721_163443.joblib\n"
     ]
    }
   ],
   "source": [
    "from scripts.logistic_regression import run_logistic_regression\n",
    "\n",
    "# Use the processed credit data from the data/processed directory\n",
    "fraud_data_path = '../data/processed/credit_minmax_scaled.csv'\n",
    "\n",
    "# Run lightgbm on the processed fraud data\n",
    "fraud_logreg_metrics = run_logistic_regression(fraud_data_path, target_col='class')\n",
    "\n",
    "# Display the results\n",
    "print(\"lightgbm on processed fraud data:\")\n",
    "for metric, value in fraud_logreg_metrics.items():\n",
    "    if metric != 'classification_report':\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(value)\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# After training the model, save it to the model/ folder with a unique name\n",
    "model_dir = \"../model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"logreg_credit_{timestamp}.joblib\"\n",
    "\n",
    "# Re-run the training to get the model object\n",
    "from scripts.logistic_regression import DataSplitter, ImbalanceHandler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv(fraud_data_path)\n",
    "splitter = DataSplitter()\n",
    "imbalance_handler = ImbalanceHandler()\n",
    "\n",
    "# Find the correct target column (case-insensitive)\n",
    "target_col = 'class'\n",
    "if target_col not in df.columns:\n",
    "    for col in df.columns:\n",
    "        if col.lower() == target_col.lower():\n",
    "            target_col = col\n",
    "            break\n",
    "\n",
    "X, y = splitter.separate_features_and_target(df, target_col)\n",
    "X_train, X_test, y_train, y_test = splitter.train_test_split(X, y, test_size=0.2, random_state=42, stratify=True)\n",
    "X_train_numeric = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64', 'int64'])\n",
    "X_train_bal, y_train_bal = imbalance_handler.apply_smote(X_train_numeric, y_train)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "joblib.dump(model, os.path.join(model_dir, model_filename))\n",
    "print(f\"Model saved to {os.path.join(model_dir, model_filename)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbb193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
